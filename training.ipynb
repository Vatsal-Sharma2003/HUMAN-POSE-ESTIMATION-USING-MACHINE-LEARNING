{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root directory is \n",
      "data directory is ../human_pose_local/archive/Human Action Recognition\n"
     ]
    }
   ],
   "source": [
    "if platform.system() == \"Darwin\":\n",
    "    root_directory = '/Users/lorenzobarbiero/Documents/GitHub/human_pose'\n",
    "    data_directory = '/Users/lorenzobarbiero/Desktop/Universit√†/VCSüêëüèÄ/Human Action Recognition'\n",
    "else:\n",
    "    root_directory = ''\n",
    "    data_directory = '../human_pose_local/archive/Human Action Recognition'\n",
    "\n",
    "print('root directory is ' + root_directory)\n",
    "print('data directory is ' + data_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df, train_perc, seed):\n",
    "    \n",
    "    shuffled_df = df.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "    \n",
    "    tr_samples = int(len(df)*train_perc)\n",
    "    \n",
    "    train_df = shuffled_df.iloc[:tr_samples]\n",
    "    \n",
    "    test_df = shuffled_df.iloc[tr_samples:]\n",
    "    \n",
    "    return [train_df,test_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "def load_data(data_directory, file_name):\n",
    "    loaded_df = pd.read_csv(data_directory+'/'+file_name)\n",
    "    # loaded_df['keypoints'] = loaded_df['keypoints'].apply(lambda x: np.array(ast.literal_eval(x)))\n",
    "    # loaded_df['obj_vector'] = loaded_df['obj_vector'].apply(lambda x: np.array(ast.literal_eval(x)))\n",
    "    return loaded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = load_data(data_directory, 'df_lightning_mobilenet.pkl')\n",
    "\n",
    "train_perc = 0.75\n",
    "train, val = train_test_split(df = merged_df, train_perc = train_perc, seed = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "      <th>category</th>\n",
       "      <th>keypoints</th>\n",
       "      <th>object</th>\n",
       "      <th>obj_label</th>\n",
       "      <th>obj_vector</th>\n",
       "      <th>obj_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Image_1.jpg</td>\n",
       "      <td>sitting</td>\n",
       "      <td>11</td>\n",
       "      <td>[ 6.16753213e-02  5.08802056e-01  5.85842179e-...</td>\n",
       "      <td>[0.60480166 0.04718776 0.03220334 0.02212468 0...</td>\n",
       "      <td>[-6.20799549e-02  9.82867330e-02 -2.71137524e-...</td>\n",
       "      <td>[array([-0.28339  ,  0.47744  ,  0.0050438, -0...</td>\n",
       "      <td>['pajama', 'shoji', 'steel drum', 'cowboy boot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Image_2.jpg</td>\n",
       "      <td>using_laptop</td>\n",
       "      <td>14</td>\n",
       "      <td>[ 0.21077526  0.9952504   0.10628459  0.998648...</td>\n",
       "      <td>[0.74187618 0.04094158 0.01289254 0.00857402 0...</td>\n",
       "      <td>[ 0.04230809 -0.10514797  0.13801953 -0.122588...</td>\n",
       "      <td>[array([ 0.34038   , -0.93576   ,  1.1605201 ,...</td>\n",
       "      <td>['studio couch', 'balance beam', 'mosquito net...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Image_3.jpg</td>\n",
       "      <td>hugging</td>\n",
       "      <td>7</td>\n",
       "      <td>[ 0.09106554  0.47515494  0.02026146  0.539173...</td>\n",
       "      <td>[0.1416007  0.13604547 0.05453948 0.04444576 0...</td>\n",
       "      <td>[-0.01161009  0.13267002  0.02587784 -0.107357...</td>\n",
       "      <td>[array([-0.28339  ,  0.47744  ,  0.0050438, -0...</td>\n",
       "      <td>['pajama', 'croquet ball', 'rapeseed', 'diaper...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Image_4.jpg</td>\n",
       "      <td>sleeping</td>\n",
       "      <td>12</td>\n",
       "      <td>[ 0.2707704   0.41700259  0.21472491  0.446423...</td>\n",
       "      <td>[0.65051037 0.06191667 0.0274907  0.0246344  0...</td>\n",
       "      <td>[-0.13456036 -0.00490448 -0.11418111 -0.185604...</td>\n",
       "      <td>[array([-1.21707   , -0.123391  , -1.12663   ,...</td>\n",
       "      <td>['neck brace', 'oxygen mask', 'nipple', 'diape...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Image_5.jpg</td>\n",
       "      <td>using_laptop</td>\n",
       "      <td>14</td>\n",
       "      <td>[ 0.02712863  0.23545875  0.00394285  0.289563...</td>\n",
       "      <td>[0.71057284 0.10088889 0.03540833 0.01631369 0...</td>\n",
       "      <td>[-0.02122975 -0.0182408  -0.07472341 -0.123700...</td>\n",
       "      <td>[array([-0.16153002, -0.20502001, -0.73711   ,...</td>\n",
       "      <td>['chain mail', 'miniskirt', 'overskirt', 'stol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12595</th>\n",
       "      <td>Image_12596.jpg</td>\n",
       "      <td>sitting</td>\n",
       "      <td>11</td>\n",
       "      <td>[ 2.35198662e-02  4.05245513e-01 -3.53041617e-...</td>\n",
       "      <td>[0.23895389 0.14317973 0.07609718 0.05683498 0...</td>\n",
       "      <td>[-4.90203351e-02  9.29452702e-02 -1.37346471e-...</td>\n",
       "      <td>[array([-0.39926 ,  0.1312  , -0.15171 ,  0.67...</td>\n",
       "      <td>['patio', 'window shade', 'library', 'folding ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12596</th>\n",
       "      <td>Image_12597.jpg</td>\n",
       "      <td>clapping</td>\n",
       "      <td>1</td>\n",
       "      <td>[ 0.03567475  0.25097162  0.00382865  0.284158...</td>\n",
       "      <td>[0.86033768 0.02151032 0.01678978 0.00953672 0...</td>\n",
       "      <td>[ 0.00781226  0.03534253  0.05144977 -0.085133...</td>\n",
       "      <td>[array([ 0.10435998,  0.29163   ,  0.459144  ,...</td>\n",
       "      <td>['lab coat', 'stethoscope', 'neck brace', 'win...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12597</th>\n",
       "      <td>Image_12598.jpg</td>\n",
       "      <td>sitting</td>\n",
       "      <td>11</td>\n",
       "      <td>[ 4.58708890e-02  5.11417568e-01  5.64771995e-...</td>\n",
       "      <td>[0.48068434 0.07919033 0.04312985 0.02671105 0...</td>\n",
       "      <td>[-0.00061709 -0.08856723 -0.05471447  0.007229...</td>\n",
       "      <td>[array([-0.13323  , -0.62751  , -0.37021  ,  0...</td>\n",
       "      <td>['jean', 'prison', 'swing', 'cellular telephon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12598</th>\n",
       "      <td>Image_12599.jpg</td>\n",
       "      <td>dancing</td>\n",
       "      <td>3</td>\n",
       "      <td>[ 2.24366948e-01  4.57129598e-01  1.92934677e-...</td>\n",
       "      <td>[0.15199172 0.06835835 0.05905863 0.04262727 0...</td>\n",
       "      <td>[ 0.00622468  0.02942869 -0.00531969 -0.142941...</td>\n",
       "      <td>[array([ 0.50444   ,  0.5363    , -0.07769001,...</td>\n",
       "      <td>['balance beam', 'knee pad', 'punching bag', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12599</th>\n",
       "      <td>Image_12600.jpg</td>\n",
       "      <td>listening_to_music</td>\n",
       "      <td>9</td>\n",
       "      <td>[ 6.21671937e-02  4.77779955e-01  6.91654859e-...</td>\n",
       "      <td>[0.15408227 0.06603773 0.04880316 0.04485467 0...</td>\n",
       "      <td>[-2.43452620e-02 -8.08917880e-02  9.81793925e-...</td>\n",
       "      <td>[array([ 0.30649   , -1.03555   ,  0.58957   ,...</td>\n",
       "      <td>['cellular telephone', 'remote control', 'clea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12600 rows √ó 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              filename               label  category  \\\n",
       "0          Image_1.jpg             sitting        11   \n",
       "1          Image_2.jpg        using_laptop        14   \n",
       "2          Image_3.jpg             hugging         7   \n",
       "3          Image_4.jpg            sleeping        12   \n",
       "4          Image_5.jpg        using_laptop        14   \n",
       "...                ...                 ...       ...   \n",
       "12595  Image_12596.jpg             sitting        11   \n",
       "12596  Image_12597.jpg            clapping         1   \n",
       "12597  Image_12598.jpg             sitting        11   \n",
       "12598  Image_12599.jpg             dancing         3   \n",
       "12599  Image_12600.jpg  listening_to_music         9   \n",
       "\n",
       "                                               keypoints  \\\n",
       "0      [ 6.16753213e-02  5.08802056e-01  5.85842179e-...   \n",
       "1      [ 0.21077526  0.9952504   0.10628459  0.998648...   \n",
       "2      [ 0.09106554  0.47515494  0.02026146  0.539173...   \n",
       "3      [ 0.2707704   0.41700259  0.21472491  0.446423...   \n",
       "4      [ 0.02712863  0.23545875  0.00394285  0.289563...   \n",
       "...                                                  ...   \n",
       "12595  [ 2.35198662e-02  4.05245513e-01 -3.53041617e-...   \n",
       "12596  [ 0.03567475  0.25097162  0.00382865  0.284158...   \n",
       "12597  [ 4.58708890e-02  5.11417568e-01  5.64771995e-...   \n",
       "12598  [ 2.24366948e-01  4.57129598e-01  1.92934677e-...   \n",
       "12599  [ 6.21671937e-02  4.77779955e-01  6.91654859e-...   \n",
       "\n",
       "                                                  object  \\\n",
       "0      [0.60480166 0.04718776 0.03220334 0.02212468 0...   \n",
       "1      [0.74187618 0.04094158 0.01289254 0.00857402 0...   \n",
       "2      [0.1416007  0.13604547 0.05453948 0.04444576 0...   \n",
       "3      [0.65051037 0.06191667 0.0274907  0.0246344  0...   \n",
       "4      [0.71057284 0.10088889 0.03540833 0.01631369 0...   \n",
       "...                                                  ...   \n",
       "12595  [0.23895389 0.14317973 0.07609718 0.05683498 0...   \n",
       "12596  [0.86033768 0.02151032 0.01678978 0.00953672 0...   \n",
       "12597  [0.48068434 0.07919033 0.04312985 0.02671105 0...   \n",
       "12598  [0.15199172 0.06835835 0.05905863 0.04262727 0...   \n",
       "12599  [0.15408227 0.06603773 0.04880316 0.04485467 0...   \n",
       "\n",
       "                                               obj_label  \\\n",
       "0      [-6.20799549e-02  9.82867330e-02 -2.71137524e-...   \n",
       "1      [ 0.04230809 -0.10514797  0.13801953 -0.122588...   \n",
       "2      [-0.01161009  0.13267002  0.02587784 -0.107357...   \n",
       "3      [-0.13456036 -0.00490448 -0.11418111 -0.185604...   \n",
       "4      [-0.02122975 -0.0182408  -0.07472341 -0.123700...   \n",
       "...                                                  ...   \n",
       "12595  [-4.90203351e-02  9.29452702e-02 -1.37346471e-...   \n",
       "12596  [ 0.00781226  0.03534253  0.05144977 -0.085133...   \n",
       "12597  [-0.00061709 -0.08856723 -0.05471447  0.007229...   \n",
       "12598  [ 0.00622468  0.02942869 -0.00531969 -0.142941...   \n",
       "12599  [-2.43452620e-02 -8.08917880e-02  9.81793925e-...   \n",
       "\n",
       "                                              obj_vector  \\\n",
       "0      [array([-0.28339  ,  0.47744  ,  0.0050438, -0...   \n",
       "1      [array([ 0.34038   , -0.93576   ,  1.1605201 ,...   \n",
       "2      [array([-0.28339  ,  0.47744  ,  0.0050438, -0...   \n",
       "3      [array([-1.21707   , -0.123391  , -1.12663   ,...   \n",
       "4      [array([-0.16153002, -0.20502001, -0.73711   ,...   \n",
       "...                                                  ...   \n",
       "12595  [array([-0.39926 ,  0.1312  , -0.15171 ,  0.67...   \n",
       "12596  [array([ 0.10435998,  0.29163   ,  0.459144  ,...   \n",
       "12597  [array([-0.13323  , -0.62751  , -0.37021  ,  0...   \n",
       "12598  [array([ 0.50444   ,  0.5363    , -0.07769001,...   \n",
       "12599  [array([ 0.30649   , -1.03555   ,  0.58957   ,...   \n",
       "\n",
       "                                               obj_words  \n",
       "0      ['pajama', 'shoji', 'steel drum', 'cowboy boot...  \n",
       "1      ['studio couch', 'balance beam', 'mosquito net...  \n",
       "2      ['pajama', 'croquet ball', 'rapeseed', 'diaper...  \n",
       "3      ['neck brace', 'oxygen mask', 'nipple', 'diape...  \n",
       "4      ['chain mail', 'miniskirt', 'overskirt', 'stol...  \n",
       "...                                                  ...  \n",
       "12595  ['patio', 'window shade', 'library', 'folding ...  \n",
       "12596  ['lab coat', 'stethoscope', 'neck brace', 'win...  \n",
       "12597  ['jean', 'prison', 'swing', 'cellular telephon...  \n",
       "12598  ['balance beam', 'knee pad', 'punching bag', '...  \n",
       "12599  ['cellular telephone', 'remote control', 'clea...  \n",
       "\n",
       "[12600 rows x 8 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[ 6.16753213e-02  5.08802056e-01  5.85842179e-04  6.02014363e-01\\n -2.33685365e-03  4.60892707e-01  6.48655463e-03  8.11203480e-01\\n  5.84213412e-04  4.67351317e-01  3.31477910e-01  1.04327512e+00\\n  1.90285340e-01  2.91586459e-01  9.19927776e-01  9.89181280e-01\\n  6.11126542e-01  1.08928956e-01  9.47085023e-01  4.90942806e-01\\n  7.22611427e-01  7.19853193e-02  9.30823147e-01  7.53619254e-01\\n  8.79170716e-01  2.77743846e-01  9.94940758e-01  9.24411893e-01\\n  8.93291771e-01 -2.87941277e-01  1.00405169e+00  2.76421845e-01\\n  9.98987019e-01  3.53196591e-01]'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df['keypoints'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(df, batch_size , shuffle=False, use_object=False, dataset_repeat=True):\n",
    "    \n",
    "    labels = df['category']\n",
    "    \n",
    "    kpoints = df['keypoints']\n",
    "\n",
    "    # merge the two arrays\n",
    "    if use_object:\n",
    "        df['input'] = df.apply(lambda x: np.concatenate((x['keypoints'], x['obj_label'])), axis=1)\n",
    "    else:\n",
    "        df['input'] = df['keypoints']\n",
    "\n",
    "    if use_object:\n",
    "        data = np.zeros((len(kpoints), 17*2+100))\n",
    "    else:    \n",
    "        data = np.zeros((len(kpoints), 17*2))\n",
    "    \n",
    "    for i, row in enumerate(df['input']): \n",
    "        data[i,:] = np.array(row)\n",
    "        \n",
    "    dataset = tf.data.Dataset.from_tensor_slices((data, labels))\n",
    "    \n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(len(data))\n",
    "\n",
    "    if dataset_repeat:        \n",
    "        dataset = dataset.repeat()\n",
    "    \n",
    "    dataset = dataset.batch(batch_size = batch_size)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_conv(df, batch_size , shuffle=False, use_object=False, dataset_repeat=True):\n",
    "    \n",
    "    labels = df['category']\n",
    "    \n",
    "    kpoints = df['keypoints'].apply(lambda x: x.reshape(17,2))\n",
    "\n",
    "    # merge the two arrays\n",
    "    if use_object:\n",
    "        df['input'] = df.apply(lambda x: [x['keypoints'], x['obj_label']])\n",
    "\n",
    "    if use_object:\n",
    "        data = np.empty(len(kpoints), dtype=object)\n",
    "    else:    \n",
    "        data = np.empty(len(kpoints), dtype=object)\n",
    "    \n",
    "    for i, row in enumerate(df['input']): \n",
    "        data[i,:] = np.array(row)\n",
    "        \n",
    "    dataset = tf.data.Dataset.from_tensor_slices((data, labels))\n",
    "    \n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(len(data))\n",
    "\n",
    "    if dataset_repeat:        \n",
    "        dataset = dataset.repeat()\n",
    "    \n",
    "    dataset = dataset.batch(batch_size = batch_size)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "zero-dimensional arrays cannot be concatenated",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m batch_s \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m\n\u001b[1;32m      2\u001b[0m use_object \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m dataset_train \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_s\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_object\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_object\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m train_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(np\u001b[38;5;241m.\u001b[39mceil(\u001b[38;5;28mlen\u001b[39m(train)\u001b[38;5;241m/\u001b[39mbatch_s))\n\u001b[1;32m      7\u001b[0m dataset_val \u001b[38;5;241m=\u001b[39m create_dataset(val, batch_s, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, use_object\u001b[38;5;241m=\u001b[39muse_object)\n",
      "Cell \u001b[0;32mIn[8], line 9\u001b[0m, in \u001b[0;36mcreate_dataset\u001b[0;34m(df, batch_size, shuffle, use_object, dataset_repeat)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# merge the two arrays\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_object:\n\u001b[0;32m----> 9\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mkeypoints\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mobj_label\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     11\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeypoints\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/frame.py:10361\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m  10347\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[1;32m  10349\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[1;32m  10350\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  10351\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10359\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m  10360\u001b[0m )\n\u001b[0;32m> 10361\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/apply.py:916\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw(engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine, engine_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_kwargs)\n\u001b[0;32m--> 916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/apply.py:1063\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1062\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1063\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1064\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1065\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_numba()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/apply.py:1081\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1078\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1079\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[1;32m   1080\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m-> 1081\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1082\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m   1083\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m   1085\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[8], line 9\u001b[0m, in \u001b[0;36mcreate_dataset.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# merge the two arrays\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_object:\n\u001b[0;32m----> 9\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mkeypoints\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mobj_label\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     11\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeypoints\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mValueError\u001b[0m: zero-dimensional arrays cannot be concatenated"
     ]
    }
   ],
   "source": [
    "batch_s = 32\n",
    "use_object = True\n",
    "\n",
    "dataset_train = create_dataset(train, batch_s, shuffle=False, use_object=use_object)\n",
    "train_steps = int(np.ceil(len(train)/batch_s))\n",
    "\n",
    "dataset_val = create_dataset(val, batch_s, shuffle=False, use_object=use_object)\n",
    "val_steps = int(np.ceil(len(val)/batch_s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "if use_object:\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.Input(shape=(17*2+100,)),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(32, activation='relu'),\n",
    "        tf.keras.layers.Dense(15, activation='softmax')\n",
    "    ])\n",
    "else:\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.Input(shape=(17*2,)),\n",
    "        tf.keras.layers.Dense(32, activation='relu'),\n",
    "        tf.keras.layers.Dense(15, activation='softmax')\n",
    "    ])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "results = model.fit(dataset_train,\n",
    "                     epochs=1000,\n",
    "                       steps_per_epoch=train_steps, \n",
    "                       validation_data=dataset_val, \n",
    "                       validation_steps=val_steps,\n",
    "                        callbacks=[early_stop_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = results.history['loss']\n",
    "\n",
    "val_loss = results.history['val_loss']\n",
    "\n",
    "train_accuracy = results.history['accuracy']\n",
    "\n",
    "val_accuracy = results.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.arange(len(train_accuracy))\n",
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, figsize=(15, 5))\n",
    "\n",
    "ax1.plot(t, train_loss, 'b')\n",
    "ax1.set_title('Train loss')\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_ylabel('Loss')\n",
    "\n",
    "ax2.plot(t, val_loss, 'g')\n",
    "ax2.set_title('Validation loss')\n",
    "ax2.set_xlabel('Epochs')\n",
    "ax2.set_ylabel('Loss')\n",
    "\n",
    "ax3.plot(t, train_accuracy, 'b')\n",
    "ax3.set_title('Training accuracy')\n",
    "ax3.set_xlabel('Epochs')\n",
    "ax3.set_ylabel('Accuracy')\n",
    "\n",
    "ax4.plot(t, val_accuracy, 'g')\n",
    "ax4.set_title('Validation accuracy')\n",
    "ax4.set_xlabel('Epochs')\n",
    "ax4.set_ylabel('Accuracy')\n",
    "\n",
    "# Adjust layout for better spacing\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on the validation set\n",
    "dataset_val = create_dataset(val, batch_s, shuffle=False, use_object=use_object, dataset_repeat=False)\n",
    "\n",
    "y_pred = model.predict(dataset_val)\n",
    "pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_true = val['category']\n",
    "\n",
    "conf_matrix = confusion_matrix(y_true, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the label from the category\n",
    "labels = merged_df.groupby('category').first()['label']\n",
    "labels = np.array(labels).tolist()\n",
    "labels[9] = 'music'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "sns.set(font_scale=1.2)  # Adjust font size\n",
    "\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap=\"Greens\", cbar=False,\n",
    "            xticklabels=labels, yticklabels=labels)\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.xlabel('Predicted labels')\n",
    "\n",
    "plt.ylabel('True labels')\n",
    "\n",
    "plt.title('Confusion Matrix Validation Set')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_specific_metrics(cm, class_labels = [i for i in range(15)]):\n",
    "    # Compute the confusion matrix\n",
    "\n",
    "    # Initialize dictionaries to hold metrics for each class\n",
    "    accuracy = {}\n",
    "    sensitivity = {}\n",
    "    specificity = {}\n",
    "    precision = {}\n",
    "\n",
    "    for idx, label in enumerate(class_labels):\n",
    "        # True positives\n",
    "        TP = cm[idx, idx]\n",
    "\n",
    "        # False positives\n",
    "        FP = cm[:, idx].sum() - TP\n",
    "\n",
    "        # False negatives\n",
    "        FN = cm[idx, :].sum() - TP\n",
    "\n",
    "        # True negatives\n",
    "        TN = cm.sum() - (TP + FP + FN)\n",
    "\n",
    "        # Calculate metrics\n",
    "        accuracy[label] = (TP + TN) / cm.sum()\n",
    "        sensitivity[label] = TP / (TP + FN) if (TP + FN) != 0 else 0\n",
    "        specificity[label] = TN / (TN + FP) if (TN + FP) != 0 else 0\n",
    "        precision[label] = TP / (TP + FP) if (TP + FP) != 0 else 0\n",
    "\n",
    "    metrics_dict = {label: {'Accuracy': accuracy[label],\n",
    "                        'Sensitivity': sensitivity[label],\n",
    "                        'Specificity': specificity[label],\n",
    "                        'Precision': precision[label]}\n",
    "                    for label in class_labels}\n",
    "\n",
    "    # Convert the dictionary to a pandas DataFrame\n",
    "    df_metrics = pd.DataFrame.from_dict(metrics_dict, orient='index')\n",
    "    df_metrics\n",
    "\n",
    "    return df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = class_specific_metrics(conf_matrix)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on the training set\n",
    "dataset_train = create_dataset(train, batch_s, shuffle=False, use_object=use_object, dataset_repeat=False)\n",
    "y_pred_train = model.predict(dataset_train, steps=train_steps)\n",
    "\n",
    "pred_train = np.argmax(y_pred_train, axis=1)\n",
    "\n",
    "# confusion matrix\n",
    "y_true_train = train['category']\n",
    "\n",
    "conf_matrix_train = confusion_matrix(y_true_train, pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "sns.set(font_scale=1.2)  # Adjust font size\n",
    "\n",
    "sns.heatmap(conf_matrix_train, annot=True, fmt='d', cmap=\"Blues\", cbar=False,\n",
    "            xticklabels=labels, yticklabels=labels)\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.xlabel('Predicted labels')\n",
    "\n",
    "plt.ylabel('True labels')\n",
    "\n",
    "plt.title('Confusion Matrix Training Set')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = class_specific_metrics(conf_matrix_train)\n",
    "df_train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
